#### 模型实现

本节将讨论我们的方法的具体实现，包括各个模型的输入输出、参数设置和训练过程。上一节的讨论可以得到我们需要实现的映射包括

$c = f(i, v),\ i_d = g(c, v), s = h(i ,v), i = m(c, s, v)$

以及为保证对抗训练的判别器，下文中会依次详细的介绍每一部分的实现和参数，以及我们应用到的两个模块SPADE和CoordConv的细节。我们的代码参考了pix2pix-cyclegan，spade，coordconv的实现细节，在整合这些模块的基础上编写了自己的模型和训练代码，实现细节开源在github/DanDoge/FYP中。

后文中我们会使用形如图？的图来描述我们的模型的具体结构，其中每一层的含义和参数意义与它们在pytorch中的定义一致，如$conv(inputnc, outputnc, kernelsize, stride, padding)​$。



##### 生成器

我们期望编码器能够从二维图像中提取出三维信息，并且通过解码器将三维信息映射回二维平面。对此，二维图像中的坐标信息是十分重要的，例如输入一辆车的侧面时，有关车轮的信息更有可能在图像的下面获取到而不是上面，解码三维信息时也同理。而卷积层由于自身的空间不变性并不能实现这种需求。为解决这种矛盾，我们将生成器中的所有卷积层替换成坐标卷积（coordconv），这种卷积现在输入变量后附加两个通道，分别包含每一个位置的x,y坐标，显式的让卷积层获得位置信息，在不同位置生成不同的输出特征。



在解码器整合内容信息和材质信息时，我们采用了SPADE模块来帮助生成。我们采用的SPADE模块由InstanceNorm和一个MLP组成，MLP负责从深度图和材质特征中估计出用来正则化特征的$\gamma$和$\beta$。通过将输入特征的均值和方差替换成估计出的统计量，我们试图在特征维度对齐生成图片的分布和训练图片的分布。不同的SAPDE模块MLP参数不同，这样我们就能利用连续的几个SAPDE模块逐渐将材质信息和内容信息整合。



##### 编码器

编码器用来实现$s = h(i, v)$，从图像中提取出和视角无关的材质特征。编码器在几个卷积模块和全局池化层之后，利用两个全连接层估计材质隐变量的均值和方差。其中一个卷积模块由coordconv和激活层组合而成，全局平均池化层将各个位置提取到的材质信息整合成全局的材质特征。在我们的实验中，材质隐变量的维度设定为64维，这足以表征材质信息。视角信息只在最开始拼接在图像上，使得输入编码器的变量通道数为$3 + 2 = 5$维。



##### 判别器

判别器采用卷积层和非线性层叠加的方式实现。每一次卷积都使用步长为2的卷积，并且倍增输出的通道数以实现在下采样的同时，不丢失原图中信息的效果，通道数最大值设定为64\*8。最后一层卷积输出1通道的结果，判别输入向量的真实性。在我们的实验中，下采样的次数为4次，对于输入的128\*128的图像最终输出长宽为8\*8的向量，每一个位置表示它所对应的原图中16\*16的部分的真实性。对于后文会叙述的一次输入两张图片的情况，每一个位置表示它对应的16\*16的部分的两张图片是否属于同一个材质。在原尺度的判别器之外，我们还增加了一个小尺度的判别器，它的输入是原尺度判别器输入1/2下采样一次的结果。它的网络结构与原尺度判别器类似，只是通道数减半，以保证每一个通道的信息量大致和原尺度相同。它的输出的每一个位置同样对应它的输入的16\*16的部分，也就是原图的32*32的部分。加入小尺度的判别器保证了输出图像在多尺度上都和目标图像有相同的统计特征，为生成器提供更多的指导。优化过程中我们对两个尺度的判别器的输出都做同样的优化：对真样本。下文中提到的判别器都指的是原尺度和小尺度判别器的组合

判别器的损失函数采用最小二乘优化（LSGAN），原文中证明了它等价于优化皮尔森卡方散度，训练更加稳定。我们尝试了其他GAN损失函数的变体，包括WGAN，对生成图像的结果没有很大影响。判别器的损失函数优化目标是使得生成器的生成结果贴近于某一个分布，而这一个分布是通过训练数据指定的。不同的训练目标对应着不同的指导分布，也就对应着不同的输入数据。在我们的训练过程中，我们希望生成器的生成结果达到下列两个目标：

- 生成高质量的图片。为此我们使用生成图片和真实图片分别作为假/真数据的代表输入判别器，这个损失函数使得生成图片能更具真实性。
- 生成具有特定材质/内容的图片。为此我们引入另一种判别器，它的输入是两张图片的拼接，即输入通道数加倍。训练时，对于RGB图片的生成任务，我们要求生成图片的材质相同，采用同一个物体在不同视角下的RGB图片作为真样本，用生成器输出的结果和一张真实图片拼接作为假样本训练；对于深度图的生成任务，我们对称的引入一个要求生成深度图的内容一致的判别器。

所以我们的网络中共有8个判别器，分别对应两个生成任务、两个目标和两种尺度的组合。

生成对抗网络的训练不稳定，可能在训练过程中出现网络崩溃的现象，这往往是判别器学习过快导致的。对此kato文在新视角生成任务种采用了一种弱化的判别器：即将原视角下重建的结果作为真样本，新视角下生成的结果作为假样本。这样做的初衷是训练初期重建的结果往往会好过新视角生成的结果，判别器能够学习到一些知识，但又不至于学习的过快。我们尝试过这种训练方式，但结果并不好。因为这样判别器学习到的分布特征其实完全来自于生成器，整个网络的监督信息依赖于对生成结果的L1/2损失函数。在我们的实验中，单独这个损失函数是不足够的，因此我们的训练过程完全采用真实图片输入。