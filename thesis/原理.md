### 实验原理

本章会详细论证我们的方法的统计原理。在介绍了我们主要使用的变分自编码器(VAE)和生成对抗网络(GAN)之后，我们将推导出本文的方法的统计基础，为下一章介绍我们的方法的具体实现做好铺垫。

生成模型旨在学习一个分布X~P(X)，其中X可能是来自一个高维空间的数据点，例如我们实验的图像数据来自128\*128\*3维的分布。根据实际应用的需要，生成模型更关心的是从P(X)中采样，而不是数值的学习到P（X），后者并不一定对前者有帮助。变分自编码器和生成对抗网络是成功的生成模型的两个例子，他们成功的利用了神经网络来拟合P(X)，并且对数据分布并没有很强的先验假设，因而成为广泛应用的生成模型。

##### 变分自编码器

变分自编码器主要可以用来无监督的学习复杂的数据分布。通过将直接采样X分解为先采样一个隐变量z，再通过学习到的映射将z映射到X的空间中，VAE将一个复杂的采样任务分解成一个从隐空间采样和一个学习映射的任务。这样做的优点有，1）因为z从属的空间往往是简单的空间，例如标准正态分布，隐空间中的采样任务很容易实现；2）映射往往用神经网络来实现，这样容易通过随机梯度下降的方法优化，并且计算量也不会十分巨大。公式化的话，VAE期望优化训练集中的每一个数据点的概率值，P(X) = \int P(X | z; \theta) P(z) dz，其中由z生成X的分布是由\theta参数化的神经网络，为方便后续推导，我们假定 P(X | z; \theta) = N(X | f(z; theta), \sigma^2 \* I)。如果直接对上式采样，将意味着很大的计算负担，并且对于大多数的z，P(X|z)都接近于0，很多样本是近似无意义的。因此，变分自编码器需要另一个函数Q(z|X)来拟合真实的P（z|X）分布，这也正是名字中变分一词的来历。其中Q分布通常也假定为正态分布，由另一个模型估计出来。这样，通过观察下式

$KL(Q(z|X) ||P(z|X)) = E_{z \sim Q}[\log Q(z|X) - \log P(z | X)]$

$KL(Q(z|X) ||P(z|X)) = E_{z \sim Q}[\log Q(z|X) - \log P(X | z) - \log P(z)] + \log P(X)$

$\log P(X) - KL(Q(z|X) | P(z|X)) = E_{z \sim Q}[\log P(X|z)] - KL(Q(z) | P(z))$

上式左边正是我们想要优化的：两项分别代表最大化训练集的概率，和最小化变分带来的误差。而上式右边两项又可以通过神经网络优化：两项分别代表重构图片的概率，在高斯假定的情况下近似为L2误差，和两个正态分布之间的KL散度。



插一张图：VAE tutorial fig1，重参数化的图



从表示学习(representation learning)的角度看，VAE学习到了高维空间图像的一个低维表示。在表示学习中，一个重要的任务是学习到一个分离(disentangle)的表示，这种表示既存储了高维空间向量的全部信息，本身又有很强的可解释性。例如对于手写字符任务，一种可行的分离表示可以是n维隐变量的第一个维度表示字符的类别，第二/三个表示字符的斜度/粗细，每一个维度表征数据集中变化的一个因子（factor of variation）。这种表示意味着我们可以通过调整一个维度来调整生成图像的某一个特征，对风格迁移任务有很大的帮助。在传统的VAE基础之上，研究者提出了不同的VAE变种来提升VAE编码的分离能力，如. Understanding disentangling in beta-vae Learning disentangled representations with wasserstein autoencoders. 他们可以看作在传统的VAE基础上加入

$\int Q(z|X) P(X) dX$

，用不同的方式实现这个后验分布，优化模型的分离能力。



上述的分离学习方法专注于在隐变量的每一个维度都分离的控制不同的变化因子。在细粒度的分离学习之外，我们也可以将VAE的隐变量分成几组，每组控制到不同的特征。A Variational U-Net for Conditional Appearance and Shape Generation文认为图像是由形状(shape)和外表(appearance)共同控制生成，文中提出了一个条件的U-Net，用形状和RGB图片生成新的图片。DISENTANGLING CONTENT AND STYLE VIA UNSUPERVISED GEOMETRY DISTILLATION文用无监督的方法分离图像中的结构和风格信息。本文同样以VAE为理论基础，专注于分离图片中几何信息和风格信息。我们在理论推导方面收到了上两文的启发，但选取了深度图表示结构信息，而不是隐变量或关键点。