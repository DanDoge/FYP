### 实验结果

本章将集中展示我们的方法的实验结果，包括进行实验的数据集，生成图片的定性定量结果和与其他方法的比较。

##### 数据集

为了公平比较，我们使用了与af相同的数据集进行实验。af文将shapenet-car分支下的模型分成两部分，分别作为训练集和测试集，训练集有xxxx个模型，测试集有yyyy个模型。对每一个模型，af在54个视角下渲染，分别是方位角0递增到340，步长为20，仰角分别取0，10，20。我们使用blender的python脚本先渲染出这些视角下的深度图和RGB图片，以减少训练时渲染的时间开销。af和3dconv开源的代码中采用了自己的渲染器，为保证实验结果的公平性，这些方法都是在我们渲染出的数据集上实验。对于真实数据，我们采用

**3D Object Representations for Fine-Grained Categorization**

中提出的汽车数据集，其中分别包含8144和8401张训练和测试的汽车图片。因为我们的模型并没有编码背景的能力，我们用预训练的场景分割算法分割出包含汽车的部分。为保证真实图片的数据分布和我们的合成图片尽可能的贴合，我们删去了物体大小过小，和物体不居中的图像。