生成三维模型的最优视图会增强人们对三维模型的理解，便利三维模型的检索和可视化，是一个具有研究价值和使用价值的问题。本文回顾了以往在生成最优视图领域的工作，提出了一个新的模型用于生成三维模型的视图，并提出了一个选择最优视角的方法。在详细描述方法原理之后，我们通过和以往方法的比较，证明了我们提出的方法的有效性。它和以往的新视角生成算法效果相当，并且能够实现图片领域的材质迁移，也能通过一些精修应用到真实图片上。基于这种方法定义的选择最优视角的算法也能够选取出材质意义上更加优秀的算法。



在上文介绍过的模型优点之外，我们的方法还有以下不足：

- 材质提取只停留在全局层面，对于细节特征并不能很好的还原。这是本文采用的卷据网络提取特征，并且像素级别生成的通病。我们观察到对于材质多样的模型，我们的方法只能迁移其中主要的或者平均的材质；而对于细粒度的特征，例如车头车尾的细节，我们的模型倾向于生成数据集中平均的特征。这可能是因为

    - 细粒度的特征只停留到卷积网络，深层的特征只留下全局的特征
    - 像素级别的生成网络的损失函数倾向于生成平均特征，这在VAE一节中有详细的讨论

    相反的，利用流的模型能够较好的保留原图中的细节特征。将材质和内容相分离的思想应用到流生成模型上可能是一个有趣的未来工作。

另外我们的工作只是在图像层面能够重建三维模型的材质信息，进一步的工作可能是利用我们对深度图的上色结果给三维模型的面上色，如何根据这一目标修改模型结构，并有效的整合多视角下的上色结果也是未来的一个工作方向。

