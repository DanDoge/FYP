### 引言



#### 研究背景



三维模型是图形学和计算机视觉方向的研究重点。近年来，三维模型的应用变得越来越广泛，从游戏界和工业界的 CAD 模型，到前沿领域的自动驾驶，使用三维模型正大大便利着业界。RGB-D 传感器的应用
也使得产生三维模型更加容易。在学术界，三维模型也有着广泛的应用：三维模型的分割、重建，以及利用三维模型强化对图片的理解。这些因素都催生了大规模三维模型库 ( 如Shapenet,Pascal3D+, ModelNet)。

在如此多的精力投入利用数据集解决问题的同时，相对少的精力投入到利用数据驱动的方法方便数据集的可视化和检索上。不同于二维图片便于观看、容易生成缩略图，三维模型在不同视角下会有不同的姿态，并且需要材质信息才能渲染出一张图片。这使得检索三维模型的数据库是一件费事的工作。ShapeNet 数据集将每一个类别的模型对齐到同一个朝向，并在固定的方向渲染了 8 张缩略图，ModelNet 数据集只提供了三维模型，这些方法并不能提供一个便捷的检索三维模型的方案。现有的处理三维模型的软件(如MeshLab)，提供用户一个拖拽视角的界面，让用户寻找最好的视角。如果能设计出生成最优视图的算法，将会便利检索三维模型数据库。

我们认为生成三维模型的最优视图至少包括两个部分，一个部分是选定最优的视角，另一部分是在这个选定的视角下渲染出带有材质的二位视图。第一个部分以往工作主要从图形学入手，通过在三维模型的顶点或是在二维视图上定义信息(熵)，取熵最大的视角作为最优视角。渲染材质的工作则集中利用了基于神经网络的生成模型，将材质生成问题定义为有条件的图片到图片翻译的问题。我们借鉴了这两方面方法的核心思想，并提出了新的生成三维模型最优视图的算法。