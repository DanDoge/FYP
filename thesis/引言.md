### 引言



#### 研究背景



三维模型是图形学和计算机视觉方向的研究重点。近年来，三维模型的应用变得越来越广泛，从游戏界和工业界的 CAD 模型，到前沿领域的自动驾驶，使用三维模型正大大便利着业界。RGB-D 传感器的应用
也使得产生三维模型更加容易。在学术界，三维模型也有着广泛的应用：三维模型的分割、重建，以及利用三维模型强化对图片的理解。这些因素都催生了大规模三维模型库 ( 如Shapenet,Pascal3D+, ModelNet)。

在如此多的精力投入利用数据集解决问题的同时，相对少的精力投入到利用数据驱动的方法方便数据集的可视化和检索上。不同于二维图片便于观看、容易生成缩略图，三维模型在不同视角下会有不同的姿态，并且需要材质信息才能渲染出一张图片。这使得检索三维模型的数据库是一件费事的工作。ShapeNet 数据集将每一个类别的模型对齐到同一个朝向，并在固定的方向渲染了 8 张缩略图，ModelNet 数据集只提供了三维模型，这些方法并不能提供一个便捷的检索三维模型的方案。现有的处理三维模型的软件(如MeshLab)，提供用户一个拖拽视角的界面，让用户寻找最好的视角。如果能设计出生成最优视图的算法，将会便利检索三维模型数据库。

我们认为生成三维模型的最优视图至少包括两个部分，一个部分是选定最优的视角，另一部分是在这个选定的视角下渲染出带有材质的二位视图。第一个部分以往工作主要从图形学入手，通过在三维模型的顶点或是在二维视图上定义信息(熵)，取熵最大的视角作为最优视角。渲染材质的工作则集中利用了基于神经网络的生成模型，将材质生成问题定义为有条件的图片到图片翻译的问题。我们借鉴了这两方面方法的核心思想，并提出了新的生成三维模型最优视图的算法。



#### 相关工作

最优视角选择

三维模型的最优视角选择任务旨在对给定的三维模型给出符合人类认知的最优的视角。这并不是一个良定义的问题，以往的研究方向往往采用在三维顶点或是二维像素上定义某种函数而将其转换为最优化问题。传统上认为最佳视角是包含最多信息的视角，不同的方法对信息的定义各不相同。在三维模型的二维视图上定义信息的文章主要包括：视角熵[11]，曲率熵[12]，轮廓熵[12]，在不同的视角的投影中取信息最大的投影作为最佳视角。[1]文中对比了几种基于几何学的方法的结果和人为标注的最优视角的差别，文章得出 MeshSaliency 和视角熵的方法是效果最好的传统方法。Mesh Saliency[13]通过在每一个三维定点定义与曲率有关的显著性，并将可见的显著性加和最大的视角定义为最佳视角。文章更加提出了一种在视角空间中类似梯度下降的方法寻找最优视角的方法，而不需在视角空间中方格搜索(grid search)最优视角。视角熵的方法关注二维投影中可见的每一个三维面片的投影面积，并将投影面积构成的分布的熵最大的视角作为最优的视角。我们认为这些方法有时并不会产生令人满意的效果。他们破坏了同一类三维模型共享同一个最佳视角的规则，并且对三维模型的建模方式很敏感。本研究首先复现了经典的传统方法，在以后的行文中，采用 Mesh Saliency 和视角熵作为传统方法的代表，和我们提出的方法作比较。



新视角生成

新视角生成旨在给定一个三维模型在一个或多个视角下的视图来生成新视角下的视图。因为不同视角下可见的像素不同，这个任务本质上是一个非良定义的问题，而需要足够强的先验知识和正则化约束来得到可接受的结果。以往解决新视角生成任务的方法大致可以分为两大类：基于几何学的和基于学习的方法。几何学的方法能够从输入图片显式的估计三维模型的结构和材质信息。Multi-view stereo方法可以通过多个视角的输入图片直接重构出三维模型。Flynn et al.提出的深度神经网络能够在不同视角的图片中进行插值。几何学的方法主要缺点是作为训练数据的三维模型难以获得，并且缺失的像素会导致错误的破洞填补(hole-filling)。基于学习的方法将新视角生成看作图片生成任务，或采取预测从原图片到目标图片的流的方式，或是采用某种正则化后直接生成每一个像素。不同的方法针对它非良定义的特性使用了不同的正则化方法，如感知损失函数，生成对抗网络的损失函数和三维信息的方式。



材质迁移

材质迁移旨在给定一张内容图片和一张材质图片，生成一张具有前者内容和后者的材质的图片。一种通用的思路是从输入图片中编码出表征内容和表征材质的向量，如一群文章。囿于成对训练数据缺失，材质迁移方法无法使用有监督的一范数或二范数损失函数，而需要采取独特的方法训练内容和材质的分离：如VGG的loss，最小化循环loss或增加独特的判别器。受dadin启发，另一种融合材质和内容的方法是从内容或材质信息中回归参数来调整神经网络中间层激活量的大小和偏移。在三维领域，将一个三维模型的材质迁移至另一三维模型可以通过直接在三维空间中生成每一个点或面片的颜色，也可以将三维模型投影至二维空间进行。前者的方法普遍较为复杂且生成结果较为模糊，本文采用类似VON的模式，将三维模型渲染为深度图后，在深度图上渲染模型的材质信息